# Fine-tuning Bert-base-cased using rotten-tomatoes dataset and embeddings MixUp augmentation method

## Краткое описание проекта
Fine-tuning модели Bert-base-cased на датасете rotten-tomatoes

Rotten-tomatoes - набор данных обзоров фильмов. Каждый отзыв характеризуется меткой 1 (положительный отзыв) и 2 (негативный отзыв) Набор данных состоит из 5331 положительных отзывов и 5331 негативных
* Обучающая часть состоит из 8530 отзывов
* Валидационная часть состоит из 1066 отзывов
* Тестовая часть состоит из 1066 отзывов

Для этапа fine-tuning была использована модель bert-base-cased. Embeddings MixUp метод увеличил размер обучающего датасета до 12031. Для получения дополнительных 3500 объектов были задействованы 7000 случайных экземпляров из датасета для получения их комбинаций.

Embeddings MixUp метод - один из методов аугментации данных для классификации текста и изображений.
Важным шагом для классификации текста является  преобразование текста в векторное представление, для этого используется transformer-based pre-trained output features. Формула аугментации MixUp на уровне эмбеддингов:

xˆ = λ * T (xi ) + (1 − λ) * T (xj ),  где T (xi ), T (xj )- векторные представления слов, полученные на выходе модели

yˆ= λ * yi + (1-λ) * yj, где yi, yj - метки
xˆ, yˆ - новый экземпляр

i,j - индексы случайно выбранных объектов из датасета 

## Структура проекта
Проект состоит из 3 основных этапов:
* __Этап подготовки__ обучающей, валидационной и тестовой частей.
Она включает в себя токенизацию текста и процесс аугментации (для обучающей выборки)
* __Тренировочный этап__
Модель bert-base-cased обучается на 12031 размеченных отзывах. Метрика - accuracy score.
Параметры обучения: 3 эпохи, размер batch для каждого устройства 8, learning rate 1e-5.
* __Этап тестирования__
Дообученная модель (при отсутствии тренировочного этапа есть возможность загрузить модель из облака) тестируется на тестовой части датасета. Для оценки качества модели используется метрика accuracy score.

## Результаты
Аналитика показывает, что дообученная модель bert-base-cased на датасете без использования аугментации embeddings MixUp методом по метрике accuracy-score позволяет получить следующие результаты:

Fine-tuning модели с использованием методом MixUp на уровне эмбеддингов позволяет получить следующие результаты: 

Таким образом, использование embeddings MixUp метода позволяет увеличить точность c 0.837 до 0.847.

## Инструкция к запуску
Для запуска проекта был подготовлен файл requirements.txt с версиями используемых пакетов и модулей

### data_preparation.py 
Загружает датасет rotten-tomatoes из модуля datasets.
Токенезирует все текстовые записи из тренировочной, валидационной и тестовой частей.
### train.py
Запускает data_preparation.py и загружает тренировочный и валидационный датасеты, загружает pre-trained  bert-base-cased, формирует тренировочные параметры и запускает fine-tuning процесс
### test.py
Запускает data_preparation.py для получения данных для тестирования и формирует из них датасет для оценки качества дообученной модели. Если был пропущен этап дообучения train.py , модель, дообученная на расширенном тренировочном датасете, полученного embeddings MixUp методом аугментации данных загружается из облака











